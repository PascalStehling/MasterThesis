\chapter{Homomorphic Encryption}

Homomorphic encryption (HE) is a specialized cryptographic system that enables the execution of operations on encrypted data in a similar fashion to that of unencrypted data. This capability allows for the outsourcing of data storage and computation to external services while maintaining the confidentiality of the data. This creates a zero-trust environment, where there is no need to trust external providers as they are unable to decrypt the data. Furthermore, the occurrence of data breaches would be effectively eliminated, as the data is always encrypted.


As described in \cite{FheImplementations}, HE algorithms can be grouped into 3 classes:
\begin{description}
  \item [Partially Homomorphic Encryption (PHE)]\hfill \\one type of operation can be performed an unlimited amount of times
  \item [Somewhat Homomorphic Encryption (SWHE)]\hfill \\some types of operations for an limited number of times
  \item [Fully Homomorphic Encryption (FHE)]\hfill \\an unlimited type of operations for an unlimited amount of times
\end{description}

As the algorithm will be used on binary data, the operations are often reduced to addition and multiplication, as with these two, all other basic operations can be done in binary space.

The Idea was first developed by Rivest et al. \cite{Rivest1978} in 1978. They also proposed an PHE scheme, based on RSA., for multiplication only. More PHE schemes were developed over time and in 2009 C. Gentry proposed the first FHE scheme \cite{Gentry2009AFH} based on a bootstrapping technique, which refreshes the ciphertext, so that the internal errors are reduced and further calculations can be done. With that, all SWHE systems can be converted into FHE systems. However, the conversion results in a significant reduction in performance due to the computational intensity of the bootstrapping operation.

In order to implement a homomorphic encryption scheme based on LWE, it is necessary to define three additional functions in addition to the three functions defined in section \ref{sec:LweProblem}:

\begin{enumerate}
  \item \textbf{Addition}: This operation takes two ciphertexts as inputs and returns a new ciphertext by adding them together.
  \item \textbf{Relinearization KeyGen}: This operation accepts a secret and a mapping value as input and generates a Relinearization Key Pair (RLK). The RLK is necessary for creating a functional multiplication algorithm for LWE-based schemes.
  \item \textbf{Multiplication}: This operation takes two ciphertexts and a RLK as inputs and performs a multiplication operation on the ciphertexts, with the help of the RLK, returning a new ciphertext.
\end{enumerate}

The binary space allows for the derivation of all other operations based on addition and multiplication. Consequently, the majority of HE schemes concentrate on developing functional versions of these operations.


\section{The R-LWE SWHE Scheme}

As previously stated, the two operations, addition and multiplication, must be implemented within the ciphertext space in order to construct an HE scheme. The aforementioned operations will first be created for the R-LWE version of the scheme, which has already been developed. Construction of addition and multiplication will be based on a modified version of the BFV scheme (\cite{bfv}).

\subsection*{Addition}

The objective is to develop a method for adding encrypted messages in such a way that the result is identical to that obtained by adding the plaintext messages. This can be achieved by adding the ciphertext together, with the error increasing linearly. Further details on this approach can be found in the BFV scheme \cite{bfv}. 

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $ct_1 = (u_1, v_2)$, $ct_2 = (u_2, v_2)$
    \RETURN $ct_{add} = ([u_1 + u_2]_q, [v_1 + v_2]_q)$
  \end{algorithmic}
  \caption{R-LWE: Addition}
  \label{alg:RlweAddition}
\end{algorithm}

The newly created $ct_{add}$ can then be used, like any other ciphertext, to be decrypted and used for other operations. However, it should be noted that the error in it has increased, which may result in the incorrect result being produced at some point.

\subsection*{Multiplication}

The process of deriving the same result for multiplication is somewhat less straightforward. In order to simplify the following derivations and explanations, the following simplification is made, based on Algorithm \ref{alg: SampleLweDecryption}:

\begin{equation}
  ct(s)_q = v-s\cdot u
  \label{eq:baseCt}
\end{equation}

Also let $ct_1$ and $ct_2$ be two ciphertext that we want to use, with $ct_1(s) = v_1-s\cdot u_1$ and $ct_2(s) = v_2-s\cdot u_2$
The multiplication of these two values results in the equation \ref{eq:ringCiphertextMultiplication}
\begin{equation}
  \begin{split}
    [ct_1(s)\cdot ct_2(s)]_q & = [(v_1-s\cdot u_1) \cdot (v_2-s\cdot u_2)]_q                                                                                              \\
                             & = [v_1\cdot v_2 - v_1\cdot u_2 \cdot s- v_2\cdot u_1\cdot s + u_1\cdot u_2\cdot s^2]_q                                                     \\
                             & = [\underbrace{v_1\cdot v_2}_{v_m} - \underbrace{(v_1\cdot u_2 + v_2\cdot u_1)}_{u_m}\cdot s + \underbrace{u_1\cdot u_2\cdot}_{x_m} s^2]_q \\
                             & = [v_m - u_m\cdot s + x_m \cdot s^2]_q
  \end{split}
  \label{eq:ringCiphertextMultiplication}
\end{equation}

Equation \ref{eq:ringCiphertextMultiplication} results in the formation of three blocks, each dependent on a different power of $s$. In comparison to Equation \ref{eq:baseCt}, it can be observed that the current equation is similar, with the exception of the additional $x_m\cdot s^2$ factor. 
A method is required to approximate $x_m\cdot s^2$ and combine it with $v_m$ and $u_m$. This will reduce the degree of the equation from two to one, which is known as relinearization. The formalization can be observed in Equation \ref{eq:relinFormalized}, where r represents an error that should be minimized to ensure successful decryption.

\begin{equation}
  [v_m - u_m\cdot s + x_m \cdot s^2]_q = [v'_m - u'_m\cdot s + r]_q
  \label{eq:relinFormalized}
\end{equation}

In order to resolve this issue, the "modulus switching" technique from \cite{bfv} will be employed. The initial step is to define a Relinearization Key ($rlk$), which masks $s^2$. In this process, the value $s^2$ will be multiplied with a new constant, $p$. This constant is essential for reducing the error that is generated when "decrypting" the $rlk$ (see equation \ref{eq:RlkDecryption}).
The form of the masked value is based on the public key, such that when $A_{rlk}$ and $b_{rlk}$ are "decrypted" with $s$, the original value $p\cdot s^2$ is obtained. The generation of this $rlk$ is described in Algorithm \ref{alg:RingRLKGeneration}.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $s$
    \STATE $A \leftarrow R_{p \cdot q}$
    \STATE $e \leftarrow \chi_R^{'}$
    \STATE $b = [A\cdot s+e+p\cdot s^2]_{p \cdot q}$
    \RETURN $rlk:=(A_{rlk}, b_{rlk})$
  \end{algorithmic}
  \caption{R-LWE: RLK Generation}
  \label{alg:RingRLKGeneration}
\end{algorithm}

Utilizing the $rlk$, $x_m\cdot s^2$ is now decomposited into two distinct components. One component, designated $xv_m$, is added to $v_m$, while the other, $xu_m$, is added to $u_m$.

\begin{equation}
  (xu_m, xv_m) = \left(\left[\left\lfloor \frac{x_m \cdot A_{rlk}}{p}  \right\rceil \right]_q, \left[\left\lfloor \frac{x_m \cdot b_{rlk}}{p}  \right\rceil \right]_q\right)
  \label{eq:ringXmSplitting}
\end{equation}

The process of "decryption," as illustrated in equation \ref{eq:RlkDecryption}, reveals that $x_m$, a random element within $R_q$, is multiplied with the error $e_{rlk}$. This results in a significant error value. To mitigate this, the error is divided by $p$, thereby reducing its impact. In order to permit the creation of $x_m \cdot s^2$, $s^2$ was multiplied by $p$ in the $rlk$.

\begin{equation}
  \begin{split}
    xv_m - xu_m \cdot s & = \left[\left\lfloor \frac{x_m \cdot b_{rlk}}{p}  \right\rceil \right]_q - \left[\left\lfloor \frac{x_m \cdot A_{rlk}}{p}  \right\rceil \right]_q \cdot s  \\
                        & \approx \left[\frac{x_m \cdot b_{rlk}}{p} - \frac{x_m \cdot A_{rlk}}{p} \cdot s\right]_q                                                                   \\
                        & \approx \left[\frac{x_m \cdot (A_{rlk}\cdot s+e_{rlk}+p\cdot s^2)}{p} - \frac{x_m \cdot A_{rlk} \cdot s}{p}\right]_q                                       \\
                        & \approx \left[\frac{x_m \cdot A_{rlk}\cdot s}{p}+\frac{x_m \cdot e_{rlk}}{p}+\frac{x_m \cdot p\cdot s^2}{p} - \frac{x_m \cdot A_{rlk} \cdot s}{p}\right]_q \\
                        & \approx \left[\frac{x_m \cdot e_{rlk}}{p}+ x_m \cdot s^2 \right]_q
  \end{split}
  \label{eq:RlkDecryption}
\end{equation}

The complete algorithm for multiplying can be found in Algorithm \ref{alg:RingMultiplication}. In order for the algorithm to function correctly, it is necessary to multiply the value of $\frac{t}{q}$ by each of the factors. Further details on this process can be found in \cite{bfv}.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $rlk=(A_{rlk}, b_{rlk})$, $ct_1 = (v_1, u_1)$, $ct_2 = (v_2, u_2)$
    \STATE $v_m = \left[\left\lfloor \frac{t}{q}\cdot (v_1 \cdot v_2)\right\rceil\right] _q $
    \STATE $u_m = \left[\left\lfloor \frac{t}{q}\cdot(v_1 \cdot u_2 + v_2 \cdot u_1)\right\rceil\right] _q$
    \STATE $x_m = \left[\left\lfloor \frac{t}{q}\cdot(u_1 \cdot u_2)\right\rceil\right] _q$
    \STATE $xu_m = \left[\left\lfloor \frac{x_m \cdot A_{rlk}}{p}  \right\rceil \right]_q$
    \STATE $xv_m = \left[\left\lfloor \frac{x_m \cdot b_{rlk}}{p}  \right\rceil \right]_q$
    \RETURN $ct_m:=(\left[u_m + xu_m\right]_q , \left[v_m + xv_m\right]_q )$
  \end{algorithmic}
  \caption{R-LWE: Multiplication}
  \label{alg:RingMultiplication}
\end{algorithm}

\section{Generalizing from R-LWE to M-LWE}

As previously stated in Section \ref{sec:TransformingLweToRlweAndMlwe}, M-LWE is a generalization of R-LWE, where matrices and vectors of polynomials are used. Consequently, the dimension $n$ will be set to a value greater than $1$. In consequence, the dimensions of nearly all variables do change (see Table \ref{table:LweKeys}). Most importantly, $\textbf{u}$ and $\textbf{s}$ will now be vectors of length $n$, instead of single polynomials. To make the difference now more visible, vectors and matrices will now be written with bold.

\subsection*{Addition}

The addition operation has no impact on the shape of u and v, and thus the same algorithm can be used as before. The only difference is that the input ciphertexts and the newly created ciphertext are of shape $R_q^{n}\times R_q$.

\subsection*{Multiplication}

In contrast, the concept of multiplication is more complex due to the necessity of dealing with changing dimensions. When equation \ref{eq:baseCt} is applied, the term $\textbf{s}\cdot \textbf{u}$ is now a dot product between two vectors, rather than a simple polynomial multiplication. The objective is, as before, to generate new $v'_m$ and $\textbf{u}'_m$ terms, which can be used for further operations or decryption. In contrast to the previous iteration, $\textbf{u}'_m$ must now be represented as a vector rather than a polynomial.

When two ciphertexts are multiplied, the resulting equation is given by equation \ref{eq:moduleCiphertextMultiplication}. Given the complexity of the aforementioned process, a brief overview of the requisite steps will be provided in the subsequent paragraphs.

\begin{equation}
  \begin{split}
    [ct_1(s)\cdot ct_2(s)]_q & = [(v_1-\textbf{s}\cdot \textbf{u}_1) \cdot (v_2-\textbf{s}\cdot \textbf{u}_2)]_q                                                                                                                                                              \\
                             & = [(v_1-\sum_{i=0}^{n-1}s_iu_{1i}) \cdot (v_2-\sum_{i=0}^{n-1}s_iu_{2i})]_q                                                                                                                                                                    \\
                             & = [v_1\cdot v_2 - v_1\cdot \sum_{i=0}^{n-1}s_iu_{2i}- v_2\cdot \sum_{i=0}^{n-1}s_iu_{1i} + \sum_{i=0}^{n-1}\sum_{j=0}^{n-1}u_{1i}u_{2j}s_is_j]_q                                                                                               \\    
                             & = [v_1\cdot v_2 - v_1\cdot \textbf{u}_2\cdot \textbf{s} - v_2\cdot \textbf{u}_1\cdot \textbf{s} + \mathrm{sum}((\textbf{u}_{1}\otimes\textbf{u}_{2})\odot(\textbf{s}\otimes\textbf{s}))]_q                                                              \\
                             & = [\underbrace{v_1\cdot v_2}_{v_m} - \underbrace{(v_1\cdot \textbf{u}_2 + v_2\cdot \textbf{u}_1)}_{\textbf{u}_m}\cdot \textbf{s} + \mathrm{sum}((\underbrace{\textbf{u}_{1}\otimes\textbf{u}_{2}}_{\textbf{X}_m})\odot(\textbf{s}\otimes\textbf{s}))]_q \\
                             & = [v_m - \textbf{u}_m\cdot \textbf{s} + \mathrm{sum}(\textbf{X}_m\odot(\textbf{s}\otimes\textbf{s}))]_q
  \end{split}
  \label{eq:moduleCiphertextMultiplication}
\end{equation}

The first technique employed was to convert the vector dot product into its sum form. As per the definition of the dot product between two vectors, it can be rewritten as a sum: $\textbf{s}\cdot \textbf{u} = \sum_{i=0}^{n-1}s_iu_i$. This step is derived from the calculations presented in \cite{ModHE}.

The subsequent step is to transform the resulting sums once more. With the single sums, this is a relatively straightforward process, as they can simply be reformulated as dot products with an additional scalar (polynomial) multiplication. As with scalar-vector multiplication, the scalar is multiplied with each value in the vector. With this, some further transformations can be made to create a new $\textbf{u}_m$, which is a vector. 

For the double sum, it is a bit more difficult process to extract a new $x_m$. The main Idea here is, that because of the double sum, essentially an $n\times n$ matrix with all combinations of $i$ and $j$ is generated and all values are then added up. For example with $n=3$ the following matrix will be created:

$$
  \sum_{i=0}^{n-1}\sum_{j=0}^{n-1}u_{1i}u_{2j}s_is_j = \mathrm{sum}\left(\begin{bmatrix}
      u_{11}u_{21}s_{1}s_{1} & u_{12}u_{21}s_{2}s_{1} & u_{13}u_{21}s_{3}s_{1} \\
      u_{11}u_{22}s_{1}s_{2} & u_{12}u_{22}s_{2}s_{2} & u_{13}u_{22}s_{3}s_{2} \\
      u_{11}u_{23}s_{1}s_{3} & u_{12}u_{23}s_{2}s_{3} & u_{13}u_{23}s_{3}s_{3} \\
    \end{bmatrix}\right)
$$

The $\mathrm{sum}$ is simply a summation of all values, which is sometimes referred to as the "grand sum." This is essentially a double dot product with a vector of length $n$, where all values are $1$, which is denoted by the symbol $1$-vector ($\textbf{1}$): $\mathrm{sum}(\textbf{X}):= \textbf{1}\cdot \textbf{X} \cdot \textbf{1} = \sum_{i=0}^{n-1}\sum_{j=0}^{n-1} \textbf{X}_{ij}$

The next step involves splitting the $n \times n$ matrix into two matrices, one for the $u$ values and one for the $s$ values. Each term in the matrix is a product of four values, which can be split apart using the Associative Law. The $\textbf{u}$ and $\textbf{s}$ values are then multiplied separately, and the two matrices are multiplied together again using element-wise multiplication, also known as the Hadamard product, denoted by the $\odot$ symbol. Finally, the individual matrices can be decomposed into vector operations. This can be achieved through the use of the outer product, also referred to as the tensor product, which is represented by the symbol $\otimes$.

\begin{align*}
  \begin{bmatrix}
    u_{11}u_{21}s_{1}s_{1} & u_{12}u_{21}s_{2}s_{1} & u_{13}u_{21}s_{3}s_{1} \\
    u_{11}u_{22}s_{1}s_{2} & u_{12}u_{22}s_{2}s_{2} & u_{13}u_{22}s_{3}s_{2} \\
    u_{11}u_{23}s_{1}s_{3} & u_{12}u_{23}s_{2}s_{3} & u_{13}u_{23}s_{3}s_{3} \\
  \end{bmatrix}
   & = \begin{bmatrix}
         u_{11}u_{21} & u_{12}u_{21} & u_{13}u_{21} \\
         u_{11}u_{22} & u_{12}u_{22} & u_{13}u_{22} \\
         u_{11}u_{23} & u_{12}u_{23} & u_{13}u_{23} \\
       \end{bmatrix} \odot \begin{bmatrix}
                             s_{1}s_{1} & s_{2}s_{1} & s_{3}s_{1} \\
                             s_{1}s_{2} & s_{2}s_{2} & s_{3}s_{2} \\
                             s_{1}s_{3} & s_{2}s_{3} & s_{3}s_{3} \\
                           \end{bmatrix}                \\
   & = (\textbf{u}_1 \otimes \textbf{u}_2) \odot (\textbf{s} \otimes \textbf{s} )
\end{align*}

Having achieved a separation between $u$ and $s$, the next step is to find a method for approximating the double sum in order to add it to $v_m$ and $\textbf{u}_m$. This needs to be done in a manner analogous to equation \ref{eq:relinFormalized}. Previously, a masking of $s^2$ was employed in order to eliminate this term. In the current context, an analogous issue arises with $s \otimes s$ and a second problem emerges, namely the shape of $v_m$ as a polynomial and $\textbf{u}_m$ as a vector.

As a first step, it is necessary to revisit the original $rlk$ generation process, as outlined in Algorithm \ref{alg:RingRLKGeneration}. In order to transform it into M-LWE, the same dimensions as those employed in the standard M-LWE key generation process are used: specifically, $\textbf{A} \in R^{n \times n}_{p \cdot q}$, $\textbf{e} \in \chi^{'n}_{R}$ and $\textbf{s} \in R^n_q$. When calculating the first part of $\textbf{b}$ we get $\textbf{A}\cdot \textbf{s} + \textbf{e}$, which is an vector in $R^n$. As the second part needs to be added to this vector, the masked part (formerly $s^2$) needs to be a vector of the same dimension. As $s \otimes s$ is a matrix of dimension $n \times n$, it cannot be used directly. However, it can be split into $n$ $n$-dimensional vectors, which can then be used instead. A similar approach must be taken with the $u_1 \otimes u_2$ matrix. The matching vectors of both matrices must be multiplied elementwise. This is a feasible approach, as all values within the matrix will be summed collectively at the final step, which can be done in any order (commutative law).

\begin{align*}
   & \mathrm{sum}\left((\textbf{u}_1 \otimes \textbf{u}_2) \odot (\textbf{s} \otimes \textbf{s} )\right)                                                             \\
   & = \mathrm{sum}\left(\begin{bmatrix}
                    u_{11}u_{21} & u_{12}u_{21} & u_{13}u_{21} \\
                    u_{11}u_{22} & u_{12}u_{22} & u_{13}u_{22} \\
                    u_{11}u_{23} & u_{12}u_{23} & u_{13}u_{23} \\
                  \end{bmatrix} \odot \begin{bmatrix}
                                        s_{1}s_{1} & s_{2}s_{1} & s_{3}s_{1} \\
                                        s_{1}s_{2} & s_{2}s_{2} & s_{3}s_{2} \\
                                        s_{1}s_{3} & s_{2}s_{3} & s_{3}s_{3} \\
                                      \end{bmatrix}\right)                                                                                 \\
   & = \mathrm{sum}\left(\begin{bmatrix}
                    u_{11}u_{21} \\
                    u_{11}u_{22} \\
                    u_{11}u_{23} \\
                  \end{bmatrix} \odot \begin{bmatrix}
                                        s_{1}s_{1} \\
                                        s_{1}s_{2} \\
                                        s_{1}s_{3} \\
                                      \end{bmatrix}
  + \begin{bmatrix}
        u_{12}u_{21} \\
        u_{12}u_{22} \\
        u_{12}u_{23} \\
      \end{bmatrix} \odot \begin{bmatrix}
                            s_{2}s_{1} \\
                            s_{2}s_{2} \\
                            s_{2}s_{3} \\
                          \end{bmatrix}
  + \begin{bmatrix}
        u_{13}u_{21} \\
        u_{13}u_{22} \\
        u_{13}u_{23} \\
      \end{bmatrix} \odot \begin{bmatrix}
                            s_{3}s_{1} \\
                            s_{3}s_{2} \\
                            s_{3}s_{3} \\
                          \end{bmatrix}\right)                                                                                                                \\
   & = \mathrm{sum}\left(\sum_{i=0}^{n-1}(\underbrace{u_{1i}\cdot \textbf{u}_2}_{\textbf{x}_{mi}}) \odot (\underbrace{s_i \cdot \textbf{s}}_{\textbf{s}'_i}) \right) \\
\end{align*}

This allows us to employ $s_i \cdot \textbf{s}$ in the $rlk$ generation algorithm \ref{alg:RingRLKGeneration}. However, this necessitates the computation of $n$ $rlk$ values, as is required for each $s_i$. The complete module $rlk$ generation process is illustrated in Algorithm \ref{alg:ModuleRLKGeneration}, where $\textbf{s}'_i$ represents the individual $s_i\cdot \textbf{s}$ values. 

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $\textbf{s}$, $\textbf{s}'$
    \STATE $\textbf{A} \leftarrow R_{p \cdot q}^{n \times n}$
    \STATE $\textbf{e} \leftarrow \chi_R^{'n}$
    \STATE $\textbf{b} = [\textbf{A}\cdot \textbf{s}+\textbf{e}+p\cdot \textbf{s}']_{p \cdot q}$
    \RETURN $rlk:=(\textbf{A}_{s'}, \textbf{b}_{s'})$
  \end{algorithmic}
  \caption{M-LWE: RLK Generation}
  \label{alg:ModuleRLKGeneration}
\end{algorithm}

As before, the $rlk$ can be used to create two values, $xu_m$ and $xv_m$. These values will be added to $\textbf{u}_m \in R^n_q$ and $v_m \in R_q$, respectively. Therefore, it is necessary for these values to have the same shape. However, as the encryption process used near identical formulas, the correct shapes will be produced automatically. Thus, equation \ref{eq:ringXmSplitting} can be translated into M-LWE, as shown in equation \ref{eq:moduleXmSplitting}.

\begin{equation}
  (\textbf{xu}_m, xv_m) = \left(\sum_{i=0}^{n-1}\left[\left\lfloor\frac{\textbf{A}_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q, \sum_{i=0}^{n-1}\left[\left\lfloor \frac{b_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q\right)
  \label{eq:moduleXmSplitting}
\end{equation}

All this can be combined now into a single M-LWE multiplication algorithm, as seen in \ref{alg:moduleMultiplication}.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $rlk=((\textbf{A}_{\textbf{s}'_0}, \textbf{b}_{\textbf{s}'_0}), \ldots ,(\textbf{A}_{\textbf{s}'_{n-1}}, \textbf{b}_{\textbf{s}'_{n-1}}))$, $ct_1 = (\textbf{u}_1, v_1)$, $ct_2 = (\textbf{u}_2, v_2)$
    \STATE $v_m = \left[\left\lfloor \frac{t}{q}\cdot (v_1 \cdot v_2)\right\rceil\right] _q $
    \STATE $\textbf{u}_m = \left[\left\lfloor \frac{t}{q}\cdot(v_1 \cdot \textbf{u}_2 + v_2 \cdot \textbf{u}_1)\right\rceil\right] _q$
    \STATE $\textbf{x}_m = \left(\left[\left\lfloor \frac{t}{q}\cdot(u_{10} \cdot \textbf{u}_2)\right\rceil\right]_q,\ldots, \left[\left\lfloor \frac{t}{q}\cdot(u_{1n-1} \cdot \textbf{u}_2)\right\rceil\right]_q\right) $
    \STATE $\textbf{xu}_m = \sum_{i=0}^{n-1}\left[\left\lfloor\frac{\textbf{A}_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q$
    \STATE $xv_m = \sum_{i=0}^{n-1}\left[\left\lfloor \frac{b_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q$
    \RETURN $ct_m:=(\left[\textbf{u}_m + \textbf{xu}_m\right]_q , \left[v_m + xv_m\right]_q )$
  \end{algorithmic}
  \caption{M-LWE: Multiplication}
  \label{alg:moduleMultiplication}
\end{algorithm}

\subsection*{Generate R-LWE from M-LWE}

One simple method for evaluating the efficacy of the generalization is to generate the R-LWE scheme with the M-LWE scheme and $n=1$. The initial step is to calculate the $rlk$. With a dimension of 1, there is only a single $rlk$, which is calculated with $s'_0 = s_0 \cdot \textbf{s} = s_0 \cdot s_0 = s^2$. It can be seen that the M-LWE $rlk(s, s^2)$ (see algorithm \ref{alg:ModuleRLKGeneration}) is identical to the R-LWE $rlk(s)$ (see algorithm \ref{alg:RingRLKGeneration}), as both $A^{1 \times 1}$ and $e^1$ are both single polynomials. As with $s$, the vector $\textbf{u}$ is a single polynomial. Consequently, the calculation of $u_m$ is identical between M-LWE (algorithm \ref{alg:moduleMultiplication}) and R-LWE (algorithm \ref{alg:RingMultiplication}). Furthermore, only a single $x_m$ value is required in M-LWE (as $n=1$), which is then used to calculate both $xu$ and $xv$, which are also single polynomials. Therefore, the entire calculation is identical to the R-LWE multiplication, which is a positive indication.


\section{Criteria for Comparing LWE based Homomorph encryption schemes}

This section outlines the  criteria for comparing the three homomorphic LWE schemes. The primary distinctions between the three LWE schemes are related to two dimension variables, matrix dimension $n$ and polynomial rank $d$. As previously outlined in section \ref{sec:TransformingLweToRlweAndMlwe}, when $n>1$ and $d=1$, an Plain-LWE scheme is obtained. Conversely, when $n=1$ and $d>1$, the resulting scheme is R-LWE, and when $n>1$ and $d>1$, the scheme is M-LWE.

The size of the output values of the different steps can be compared based on these two dimension variables. The outputs in question are the secret key $sk$, the public key $pk$, the relinearization key $rlk$ and the ciphertext $ct$.

% Variable sizes based on n and d
% SK Size
% PK Size (including rlk)
% CT size

To facilitate a comparative analysis of the models' performance, an example implementation in Python will be constructed and the resulting data will be evaluated. As the same algorithm, with varying dimensions ($n$ and $d$), can be utilized to describe all three schemes, the relative performance between them can be effectively assessed. However, given that Python is a relatively slow-performing language and the algorithm is not optimized, the absolute values may not be entirely meaningful. Nevertheless, the relative performance between the schemes should remain highly comparable.

Unless otherwise indicated, all performance tests will be conducted on all algorithms, specifically: \textit{KeyGen (with )}, \textit{Encryption}, \textit{Decryption}, \textit{Addition} and \textit{Multiplication}. The first stage of the testing process will be to assess the performance of each model in isolation, with the results expressed in terms of the dimension variables $n$ and $d$, as well as the modulus $q$ and $p$ (where applicable). Subsequently, the objective will be to evaluate the relative performance of the various algorithms by comparing them against each other, with the same modulus values employed in each comparison. 

% Practical Test - Performance Comparison based on n,d,q,p
% KeyGen (with RLK)
% Encryption
% Addition
% Multiplication
% Decryption

Furthermore, the addition and multiplicative depth should be identified based on the variables. This allows for the assessment of the number of consecutive calculations that can be performed while maintaining the ability to successfully decrypt the ciphertext. To enhance the precision of the predictions, it is essential to examine the evolution of the errors associated with addition and multiplication. This enables a more accurate understanding of the impact of the variables and depth on the outcomes.


% Practical Test - Error Development - Max Rounds based on n,d,q,p 
% Addition
% Multiplication

% error development (linear/quadratic) test?
% Addition
% Multiplication

A comparative analysis of the security features of the various schemes will not be undertaken, as it would require a significant investment of time and resources that would exceed the scope of this thesis.