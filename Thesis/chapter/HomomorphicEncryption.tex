\chapter{Homomorphic Encryption}

This chapter will present a general overview of the concept of homomorphic encryption (HE). Subsequently, the encryption scheme developed in the previous chapter will be extended to create a homomorphic encryption scheme based on an already existing HE scheme. This will result in an R-LWE-based homomorphic encryption scheme. The forthcoming and novel step will be to generalise the concepts of the R-LWE-based HE scheme into an M-LWE-based one. Finally, a brief overview will be provided of additional criteria for comparing HE schemes with one another.

\section{Introduction to Homomorphic Encryption}

Homomorphic encryption is a specialized cryptographic system that enables the execution of operations on encrypted data in a manner analogous to that of unencrypted data. Such operations may include, but are not limited to, addition and multiplication. This capability permits the outsourcing of data storage and computation to external services while maintaining the confidentiality of the data. This results in the formation of a zero-trust environment, wherein the necessity for trust in external providers is negated due to their inability to decrypt the data, while they remain capable of working with it. Moreover, the occurrence of data breaches would be effectively eliminated, as the data is always encrypted.

The concept was initially proposed by Rivest et al. in 1978 \cite{Rivest1978}. The authors proposed a homomorphic encryption (HE) scheme based on RSA, which is able to perform multiplication operations. This allows for the multiplication of two ciphertexts, each encrypted with the same RSA private key, with the result of the multiplication being retrievable after decryption. This result will be identical to that which would be obtained if the two ciphertexts were multiplied unencrypted. A system that is capable of performing a single operation (e.g., multiplication) for an unlimited amount of times is referred to as \textbf{Partially Homomorphic Encryption (PHE)}  \cite{FheImplementations, SurveyOfHomomorphicEncryption}.Similarly, the same principle can also be observed with the El Gamal cryptosystem \cite{ElGamal} for multiplication or the Paillier cryptosystem \cite{Paillier} for addition. If an encryption scheme with the capacity to perform addition and multiplication on a single ciphertext can be constructed, then fully powered compute engines can be created using homomorphic circuits based on NAND gates, which can be constructed from addition and multiplication in binary space. \\
But for a long time, it was not feasible to integrate addition and multiplication into a unified encryption scheme until the advent of the BGN scheme in 2005 \cite{BGN}. The scheme allows for the realization of an arbitrary number of additions and a single multiplication. This novel scheme can be classified as a  \textbf{Somewhat Homomorphic Encryption (SWHE)}  scheme. Such schemes permit the execution of multiple types of operations, although only a limited number of times.

In 2009, C. Gentry introduced the first  \textbf{Fully Homomorphic Encryption (FHE)} scheme \cite{Gentry2009AFH}. The scheme was based on an ideal lattice and enabled the execution of addition and multiplication, which could be performed an unlimited number of times. But the primary factor contributing to the initial success of the first FHE scheme was the process of bootstrapping. The concept is to execute the decryption process, but not with the conventional secret key, but rather with an encrypted version of the secret key, frequently referred to as a "refreshing key." The decryption is performed in a homomorphic manner on the ciphertext. This results in the generation of a new ciphertext, wherein the internal error is reduced while still maintaining encryption. The new ciphertext can then be subjected to further operations, and if the error increases, the bootstrapping technique can be re-executed. This allows for the possibility of performing an unlimited number of computations, provided that the bootstrapping process is repeated at regular intervals. However, there are two significant drawbacks to this approach. Firstly, the bootstrapping process is highly resource-intensive, which can lead to suboptimal performance. Secondly, the new refresh key must be transmitted alongside the private key, increasing the amount of data that needs to be sent. Furthermore, if an attacker is able to decrypt the refresh key, they gain access to the secret key. 


\begin{table}
  \caption{Comparison of the three different types of homomorphic encryption}
  \label{table:HeTypeComparison}
  \begin{tabular}{|p{5cm}|p{2.8cm}|p{2.1cm}|p{3cm}|}
    \toprule
    HE Type                                         & Operations                           & Number of consecutive operations & Examples                                                                           \\
    \midrule
    Partially Homomorphic \newline Encryption (PHE) & addition \textbf{OR} multiplication  & unlimited                        & ElGamal \cite{ElGamal}, \newline RSA \cite{RSA}, \newline Paillier \cite{Paillier} \\
    \midrule
    Somewhat Homomorphic \newline Encryption (SWHE) & addition \textbf{AND} multiplication & limited                          & BGN \cite{BGN}                                                                     \\
    \midrule
    Fully Homomorphic \newline Encryption (FHE)     & addition \textbf{AND} multiplication & unlimited                        & BVF \cite{bfv},\newline LTV \cite{LTV}                                             \\
    \bottomrule
  \end{tabular}
\end{table}

By employing this bootstrapping technique, SWHE schemes can be transformed into FHE schemes, as they are capable of reducing their own internal error. This innovation has led to the development of numerous new FHE encryption schemes in the subsequent years. In 2011, Brakerski and Vaikuntanathan published two new FHE schemes based on the bootstrapping technique. One was based on LWE \cite{FirstLweFHE} and the other on R-LWE \cite{FirstRLweFHE}. Subsequently, numerous enhancements have been proposed (for further details, please see \cite{SurveyOfHomomorphicEncryption}, \cite{FheImplementations} or \cite{FHESurvey}). One such enhanced scheme was the BFV scheme (also called just FV scheme) \cite{bfv}, which will be used to build the HE scheme based on the encryption scheme build in the last chapter.


\section{Creating an Somewhat Homomorphic Encryption scheme}

In this section, the R-LWE based encryption scheme from section \ref{sec:TransformingLweToRlweAndMlwe} will be extend to create an SWHE scheme. In order to implement a homomorphic encryption scheme based on LWE, it is necessary to define three additional functions in addition to the three functions defined in section \ref{sec:LweProblem}:

\begin{enumerate}
  \item \textbf{Addition}: This operation takes two ciphertexts as inputs and returns a new ciphertext by adding them together.
  \item \textbf{Relinearization KeyGen}: This operation accepts a secret and a mapping value as input and generates a Relinearization Key ($rlk$). The $rlk$ is necessary for creating a functional multiplication algorithm for LWE-based schemes. In other HE schemes, such a process is often called evaluation key. In this context we use the more specific term relinearization key.
  \item \textbf{Multiplication}: This operation takes two ciphertexts and a $rlk$ as inputs and performs a multiplication operation on the ciphertexts, with the help of the $rlk$, returning a new ciphertext.
\end{enumerate}

The construction of the addition and multiplication operations will be based on a slightly modified version of the BFV scheme \cite{bfv}. The objective is to develop a fully functional SWHE scheme that can subsequently be generalized to M-LWE. The step of creating a FHE scheme using bootstrapping will not be addressed in this thesis, as it was not feasible to incorporate it within the scope of this work. However, given that bootstrapping is based on homomorphic operations, as long as these are successfully implemented, it should be possible to also construct the bootstrapping process.

\subsection*{Addition}

The objective is to develop a method for adding encrypted messages in such a way that the result is identical to that obtained by adding the plaintext messages. This can be achieved by simply adding the matching ciphertext variables together. The resulting error is thus increased linearly, as the errors from both ciphertexts are simply added together. Further details on this approach can be found in the BFV scheme.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $ct_1 = (u_1, v_2)$, $ct_2 = (u_2, v_2)$
    \RETURN $ct_{add} = ([u_1 + u_2]_q, [v_1 + v_2]_q)$
  \end{algorithmic}
  \caption{R-LWE: Addition}
  \label{alg:RlweAddition}
\end{algorithm}

The newly created $ct_{add}$ can then be employed, like any other ciphertext, for decryption or subsequent utilization in other operations. However, it is important to acknowledge that the error in it has increased, which may potentially result in the generation of an incorrect decrypted message at some point.

\subsection*{Multiplication}

Generating a functional multiplication operation in ciphertext space is a more complex process. To simplify the subsequent derivations and explanations, a simplification is made based on Algorithm \ref{alg: SampleLweDecryption} and can be seen in equation \ref{eq:baseCt}.

\begin{equation}
  ct(s)_q = v-s\cdot u
  \label{eq:baseCt}
\end{equation}

Also let $ct_1$ and $ct_2$ be two ciphertext that we want to use, with $ct_1(s) = v_1-s\cdot u_1$ and $ct_2(s) = v_2-s\cdot u_2$. The multiplication of these two values results in the equation \ref{eq:ringCiphertextMultiplication}
\begin{equation}
  \begin{split}
    [ct_1(s)\cdot ct_2(s)]_q & = [(v_1-s\cdot u_1) \cdot (v_2-s\cdot u_2)]_q                                                                                              \\
                             & = [v_1\cdot v_2 - v_1\cdot u_2 \cdot s- v_2\cdot u_1\cdot s + u_1\cdot u_2\cdot s^2]_q                                                     \\
                             & = [\underbrace{v_1\cdot v_2}_{v_m} - \underbrace{(v_1\cdot u_2 + v_2\cdot u_1)}_{u_m}\cdot s + \underbrace{u_1\cdot u_2\cdot}_{x_m} s^2]_q \\
                             & = [v_m - u_m\cdot s + x_m \cdot s^2]_q
  \end{split}
  \label{eq:ringCiphertextMultiplication}
\end{equation}

Equation \ref{eq:ringCiphertextMultiplication} results in the formation of three blocks, each dependent on a different power of $s$ ($s^0=1$, $s^1$ and $s^2$). In comparison to Equation \ref{eq:baseCt}, it can be observed that the current equation is similar, with the exception of the additional $x_m\cdot s^2$ factor. A method is required to approximate $x_m\cdot s^2$ and combine it with $v_m$ and $u_m$, in order to reduce the degree of the equation from two to one. This process is known as relinearization. The formalization can be observed in Equation \ref{eq:relinFormalized}, where $v'_m$ and $u'_m$ are extended to include $x_m\cdot s^2$ and $r$ represents the error that is created in this process, which should be minimized to ensure successful decryption. 

\begin{equation}
  [v_m - u_m\cdot s + x_m \cdot s^2]_q = [v'_m - u'_m\cdot s + r]_q
  \label{eq:relinFormalized}
\end{equation}

In order to resolve this issue, the \textit{modulus switching} technique from BFV will be employed. The initial step is to define a Relinearization Key ($rlk$), which masks $s^2$. In this process, the value $s^2$ will be multiplied with a new constant, $p$. This constant is essential for reducing the error that is generated when ``decrypting'' the $rlk$ (see equation \ref{eq:RlkDecryption}).
The form of the masked value is based on the public key (see algorithm \ref{alg: SampleLweKeyGen}), such that when $A_{rlk}$ and $b_{rlk}$ are ``decrypted'' with $s$, by putting them in equation \ref{eq:baseCt}, the original value $p\cdot s^2$ is obtained. The generation of this $rlk$ is described in Algorithm \ref{alg:RingRLKGeneration}.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $s$
    \STATE $A \leftarrow R_{p \cdot q}$
    \STATE $e \leftarrow \chi_R^{'}$
    \STATE $b = [A\cdot s+e+p\cdot s^2]_{p \cdot q}$
    \RETURN $rlk:=(A_{rlk}, b_{rlk})$
  \end{algorithmic}
  \caption{R-LWE: $rlk$ Generation}
  \label{alg:RingRLKGeneration}
\end{algorithm}

Utilizing the $rlk$, $x_m\cdot s^2$ is now decomposited into two distinct components. One component, designated $xv_m$, is added to $v_m$, while the other, $xu_m$, is added to $u_m$.

\begin{equation}
  (xu_m, xv_m) = \left(\left[\left\lfloor \frac{x_m \cdot A_{rlk}}{p}  \right\rceil \right]_q, \left[\left\lfloor \frac{x_m \cdot b_{rlk}}{p}  \right\rceil \right]_q\right)
  \label{eq:ringXmSplitting}
\end{equation}

The process of ``decryption'', as illustrated in equation \ref{eq:RlkDecryption}, reveals that $x_m$, a random element within $R_q$, is multiplied with the error $e_{rlk}$. This means, in worst case $x_m = q-1$, which is then multiplied with an small error, for example $1$. This would mean the error is nearly $q$, but as discussed in section \ref{sec:Lwe-Encryption}, the error should not be bigger than $\frac{q}{4}$, otherwise the decryption does not work. To mitigate this, the error is divided by $p$, thereby reducing its impact. In order to permit the creation of $x_m \cdot s^2$, $s^2$ was multiplied by $p$ in the $rlk$ to reverse the effect of dividing by $p$ later on.

\begin{equation}
  \begin{split}
    xv_m - xu_m \cdot s & = \left[\left\lfloor \frac{x_m \cdot b_{rlk}}{p}  \right\rceil \right]_q - \left[\left\lfloor \frac{x_m \cdot A_{rlk}}{p}  \right\rceil \right]_q \cdot s  \\
                        & \approx \left[\frac{x_m \cdot b_{rlk}}{p} - \frac{x_m \cdot A_{rlk}}{p} \cdot s\right]_q                                                                   \\
                        & \approx \left[\frac{x_m \cdot (A_{rlk}\cdot s+e_{rlk}+p\cdot s^2)}{p} - \frac{x_m \cdot A_{rlk} \cdot s}{p}\right]_q                                       \\
                        & \approx \left[\frac{x_m \cdot A_{rlk}\cdot s}{p}+\frac{x_m \cdot e_{rlk}}{p}+\frac{x_m \cdot p\cdot s^2}{p} - \frac{x_m \cdot A_{rlk} \cdot s}{p}\right]_q \\
                        & \approx \left[\frac{x_m \cdot e_{rlk}}{p}+ x_m \cdot s^2 \right]_q
  \end{split}
  \label{eq:RlkDecryption}
\end{equation}

The complete algorithm for multiplying can be found in Algorithm \ref{alg:RingMultiplication}. In order for the algorithm to function correctly, it is necessary to multiply each of the factors by the value of $\frac{2}{q}$. Further details on this process can be found in the BFV paper \cite{bfv}.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $rlk=(A_{rlk}, b_{rlk})$, $ct_1 = (v_1, u_1)$, $ct_2 = (v_2, u_2)$
    \STATE $v_m = \left[\left\lfloor \frac{2}{q}\cdot (v_1 \cdot v_2)\right\rceil\right] _q $
    \STATE $u_m = \left[\left\lfloor \frac{2}{q}\cdot(v_1 \cdot u_2 + v_2 \cdot u_1)\right\rceil\right] _q$
    \STATE $x_m = \left[\left\lfloor \frac{2}{q}\cdot(u_1 \cdot u_2)\right\rceil\right] _q$
    \STATE $xu_m = \left[\left\lfloor \frac{x_m \cdot A_{rlk}}{p}  \right\rceil \right]_q$
    \STATE $xv_m = \left[\left\lfloor \frac{x_m \cdot b_{rlk}}{p}  \right\rceil \right]_q$
    \RETURN $ct_m:=(\left[u_m + xu_m\right]_q , \left[v_m + xv_m\right]_q )$
  \end{algorithmic}
  \caption{R-LWE: Multiplication}
  \label{alg:RingMultiplication}
\end{algorithm}

\section{Generalizing from R-LWE to M-LWE}
\label{sec:GeneralizingToMLWE}

The objective in this section is to extend the algorithms defined in the previous section in order to make them applicable to M-LWE. As previously stated in section \ref{sec:TransformingLweToRlweAndMlwe}, M-LWE is a generalization of R-LWE, where matrices and vectors of polynomials are used. Consequently, the dimension $n$ will be set to a value greater than $1$. In consequence, the dimensions of nearly all variables do change (see Table \ref{table:LweDiffs}). Most importantly, $\textbf{u}$ and $\textbf{s}$ will now be vectors of length $n$, instead of single polynomials.

\subsection*{Addition}

The addition operation has no impact on the shape of u and v, and thus the same algorithm can be used as before. The only difference is that the input ciphertexts and the newly created ciphertext are of shape $R_q^{n}\times R_q$.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $ct_1 = (\textbf{u}_1, v_2)$, $ct_2 = (\textbf{u}_2, v_2)$
    \RETURN $ct_{add} = ([\textbf{u}_1 + \textbf{u}_2]_q, [v_1 + v_2]_q)$
  \end{algorithmic}
  \caption{M-LWE: Addition}
  \label{alg:MlweAddition}
\end{algorithm}

\subsection*{Multiplication}

In contrast, the concept of multiplication is more complex due to the necessity of dealing with changing dimensions. When equation \ref{eq:baseCt} is applied, the term $\textbf{s}\cdot \textbf{u}$ is now a dot product between two vectors, rather than a simple polynomial multiplication. The objective is, as before, to generate new $v'_m$ and $\textbf{u}'_m$ terms, which can be used for further operations or decryption. In contrast to the previous iteration, $\textbf{u}'_m$ must now be represented as a vector rather than a polynomial.

The equation resulting from the multiplication of two ciphertexts is given by equation \ref{eq:moduleCiphertextMultiplication}. Given the complexity of this equation and process, a brief overview of the requisite steps will be provided in the subsequent paragraphs.

\begin{equation}
  \begin{split}
    [ct_1(s)\cdot ct_2(s)]_q & = [(v_1-\textbf{s}\cdot \textbf{u}_1) \cdot (v_2-\textbf{s}\cdot \textbf{u}_2)]_q                                                                                                                                                                       \\
                             & = [(v_1-\sum_{i=0}^{n-1}s_iu_{1i}) \cdot (v_2-\sum_{i=0}^{n-1}s_iu_{2i})]_q                                                                                                                                                                             \\
                             & = [v_1\cdot v_2 - v_1\cdot \sum_{i=0}^{n-1}s_iu_{2i}- v_2\cdot \sum_{i=0}^{n-1}s_iu_{1i} + \sum_{i=0}^{n-1}\sum_{j=0}^{n-1}u_{1i}u_{2j}s_is_j]_q                                                                                                        \\    
                             & = [v_1\cdot v_2 - v_1\cdot \textbf{u}_2\cdot \textbf{s} - v_2\cdot \textbf{u}_1\cdot \textbf{s} + \mathrm{sum}((\textbf{u}_{1}\otimes\textbf{u}_{2})\odot(\textbf{s}\otimes\textbf{s}))]_q                                                              \\
                             & = [\underbrace{v_1\cdot v_2}_{v_m} - \underbrace{(v_1\cdot \textbf{u}_2 + v_2\cdot \textbf{u}_1)}_{\textbf{u}_m}\cdot \textbf{s} + \mathrm{sum}((\underbrace{\textbf{u}_{1}\otimes\textbf{u}_{2}}_{\textbf{X}_m})\odot(\textbf{s}\otimes\textbf{s}))]_q \\
                             & = [v_m - \textbf{u}_m\cdot \textbf{s} + \mathrm{sum}(\textbf{X}_m\odot(\textbf{s}\otimes\textbf{s}))]_q
  \end{split}
  \label{eq:moduleCiphertextMultiplication}
\end{equation}

The first technique employed was to convert the vector dot product into its sum form. As per the definition of the dot product between two vectors, it can be rewritten as a sum: $\textbf{s}\cdot \textbf{u} = \sum_{i=0}^{n-1}s_iu_i$. This step is derived from the calculations presented in \cite{ModHE}.\\
The subsequent step is to transform the resulting sums once more. With the single sums, this is a relatively straightforward process, as they can simply be reformulated as dot products with an additional scalar (polynomial) multiplication. Essentially just reverting the previous step. With some bracketing and factoring out $s$, a new vector $\textbf{u}_m$ can be created. \\
For the double sum, it is a bit more difficult process to extract a new $x_m$. The main Idea here is, that because of the double sum, an $n\times n$ matrix with all combinations of $i$ and $j$ is generated and all values are then added up. For example with $n=3$ the following matrix will be created:

$$
  \sum_{i=0}^{n-1}\sum_{j=0}^{n-1}u_{1i}u_{2j}s_is_j = \mathrm{sum}\left(\begin{bmatrix}
      u_{11}u_{21}s_{1}s_{1} & u_{12}u_{21}s_{2}s_{1} & u_{13}u_{21}s_{3}s_{1} \\
      u_{11}u_{22}s_{1}s_{2} & u_{12}u_{22}s_{2}s_{2} & u_{13}u_{22}s_{3}s_{2} \\
      u_{11}u_{23}s_{1}s_{3} & u_{12}u_{23}s_{2}s_{3} & u_{13}u_{23}s_{3}s_{3} \\
    \end{bmatrix}\right)
$$

The $\mathrm{sum}$ operation is simply a summation of all values, which is sometimes referred to as the \textit{grand sum}. This is just a double dot product with a vector of length $n$, where all values are $1$, which is denoted by the symbol $1$-vector ($\textbf{1}$): $\mathrm{sum}(\textbf{X}):= \textbf{1}\cdot \textbf{X} \cdot \textbf{1} = \sum_{i=0}^{n-1}\sum_{j=0}^{n-1} \textbf{X}_{ij}$

The next step involves splitting the $n \times n$ matrix into two matrices, one for the $u$ values and one for the $s$ values. This can be seen in the equation below. Each term in the matrix is a product of four values, which can be split apart using the Associative Law. The $\textbf{u}$ and $\textbf{s}$ values are then multiplied separately, and the two matrices are multiplied together again using element-wise multiplication, also known as the Hadamard product, denoted by the $\odot$ symbol. Finally, the individual matrices can be decomposed into vector operations. This can be achieved through the use of the outer product, also referred to as the tensor product, which is represented by the symbol $\otimes$.

\begin{align*}
  \begin{bmatrix}
    u_{11}u_{21}s_{1}s_{1} & u_{12}u_{21}s_{2}s_{1} & u_{13}u_{21}s_{3}s_{1} \\
    u_{11}u_{22}s_{1}s_{2} & u_{12}u_{22}s_{2}s_{2} & u_{13}u_{22}s_{3}s_{2} \\
    u_{11}u_{23}s_{1}s_{3} & u_{12}u_{23}s_{2}s_{3} & u_{13}u_{23}s_{3}s_{3} \\
  \end{bmatrix}
   & = \begin{bmatrix}
         u_{11}u_{21} & u_{12}u_{21} & u_{13}u_{21} \\
         u_{11}u_{22} & u_{12}u_{22} & u_{13}u_{22} \\
         u_{11}u_{23} & u_{12}u_{23} & u_{13}u_{23} \\
       \end{bmatrix} \odot \begin{bmatrix}
                             s_{1}s_{1} & s_{2}s_{1} & s_{3}s_{1} \\
                             s_{1}s_{2} & s_{2}s_{2} & s_{3}s_{2} \\
                             s_{1}s_{3} & s_{2}s_{3} & s_{3}s_{3} \\
                           \end{bmatrix}                \\
   & = (\textbf{u}_1 \otimes \textbf{u}_2) \odot (\textbf{s} \otimes \textbf{s} )
\end{align*}

When doing all these steps, a separation between $\textbf{u}$ and $\textbf{s}$ is achieved. The new factor $\textbf{u}_1 \otimes \textbf{u}_2$ will be the new matrix $\textbf{X}_m$, as shown in equation \ref{eq:moduleCiphertextMultiplication}.

The next step is to find a method for approximating the double sum in order to add it to $v_m$ and $\textbf{u}_m$. This needs to be done in a manner analogous to equation \ref{eq:relinFormalized}. Previously, a masking of $s^2$ was employed in order to eliminate this term. In the current context, an analogous issue arises with $s \otimes s$ and a second problem emerges, namely the shape of $v_m$ as a polynomial and $\textbf{u}_m$ as a vector. \\
As a first step, it is necessary to revisit the original $rlk$ generation process, as outlined in Algorithm \ref{alg:RingRLKGeneration}. In order to transform it into M-LWE, the same dimensions as those employed in the standard M-LWE key generation process are used: specifically, $\textbf{A} \in R^{n \times n}_{p \cdot q}$ and $\textbf{e}, \textbf{s} \in \chi^{'n}_{R}$. The original equation was $b = [A\cdot s+e+p\cdot s^2]_{p \cdot q}$. When calculating the first part of $\textbf{b}$ we get $\textbf{A}\cdot \textbf{s} + \textbf{e}$, which is now an vector in $R^n$. As the second part needs to be added to this vector, the masked part (formerly $s^2$) needs to be a vector of the same dimension. As $\textbf{s} \otimes \textbf{s}$ is a matrix of dimension $n \times n$, it cannot be used directly. However, it can be split into $n$ $n$-dimensional vectors, which can then be used instead. A similar approach must be taken with the $\textbf{u}_1 \otimes \textbf{u}_2$ matrix. The matching vectors of both matrices must be multiplied elementwise. This is a feasible approach, as all values within the matrix will be summed collectively at the final step, which can be done in any order (commutative law). This process is shown in the equation below and with it, the $\textbf{X}_m$ matrix is split into $n$ $n$-dimensional $\textbf{x}_{mi}$ vectors and there corresponding secret vectors $\textbf{s}'_i$ are created.

\begin{align*}
   & \mathrm{sum}\left((\textbf{u}_1 \otimes \textbf{u}_2) \odot (\textbf{s} \otimes \textbf{s} )\right)                                                             \\
   & = \mathrm{sum}\left(\begin{bmatrix}
                             u_{11}u_{21} & u_{12}u_{21} & u_{13}u_{21} \\
                             u_{11}u_{22} & u_{12}u_{22} & u_{13}u_{22} \\
                             u_{11}u_{23} & u_{12}u_{23} & u_{13}u_{23} \\
                           \end{bmatrix} \odot \begin{bmatrix}
                                                 s_{1}s_{1} & s_{2}s_{1} & s_{3}s_{1} \\
                                                 s_{1}s_{2} & s_{2}s_{2} & s_{3}s_{2} \\
                                                 s_{1}s_{3} & s_{2}s_{3} & s_{3}s_{3} \\
                                               \end{bmatrix}\right)                                                                                 \\
   & = \mathrm{sum}\left(\begin{bmatrix}
                             u_{11}u_{21} \\
                             u_{11}u_{22} \\
                             u_{11}u_{23} \\
                           \end{bmatrix} \odot \begin{bmatrix}
                                                 s_{1}s_{1} \\
                                                 s_{1}s_{2} \\
                                                 s_{1}s_{3} \\
                                               \end{bmatrix}
  + \begin{bmatrix}
        u_{12}u_{21} \\
        u_{12}u_{22} \\
        u_{12}u_{23} \\
      \end{bmatrix} \odot \begin{bmatrix}
                            s_{2}s_{1} \\
                            s_{2}s_{2} \\
                            s_{2}s_{3} \\
                          \end{bmatrix}
  + \begin{bmatrix}
        u_{13}u_{21} \\
        u_{13}u_{22} \\
        u_{13}u_{23} \\
      \end{bmatrix} \odot \begin{bmatrix}
                            s_{3}s_{1} \\
                            s_{3}s_{2} \\
                            s_{3}s_{3} \\
                          \end{bmatrix}\right)                                                                                                                         \\
   & = \mathrm{sum}\left(u_{11} \cdot\begin{bmatrix}
                                        u_{21} \\
                                        u_{22} \\
                                        u_{23} \\
                                      \end{bmatrix} \odot s_{1}\cdot\begin{bmatrix}
                                                                        s_{1} \\
                                                                        s_{2} \\
                                                                        s_{3} \\
                                                                      \end{bmatrix}
  + u_{12}\cdot \begin{bmatrix}
                   u_{21} \\
                   u_{22} \\
                   u_{23} \\
                 \end{bmatrix} \odot s_{2}\cdot\begin{bmatrix}
                                                   s_{1} \\
                                                   s_{2} \\
                                                   s_{3} \\
                                                 \end{bmatrix}
  + u_{13}\cdot\begin{bmatrix}
                  u_{21} \\
                  u_{22} \\
                  u_{23} \\
                \end{bmatrix} \odot s_{3}\cdot\begin{bmatrix}
                                                  s_{1} \\
                                                  s_{2} \\
                                                  s_{3} \\
                                                \end{bmatrix}\right)                                                                                                \\
   & = \mathrm{sum}\left(\sum_{i=0}^{n-1}(\underbrace{u_{1i}\cdot \textbf{u}_2}_{\textbf{x}_{mi}}) \odot (\underbrace{s_i \cdot \textbf{s}}_{\textbf{s}'_i}) \right) \\
\end{align*}

In order to use $s_i \cdot \textbf{s} = \textbf{s}'_i$ in the $rlk$ generation, the fixed $s^2$ in the original $rlk$ generation algorithm \ref{alg:RingRLKGeneration} needs to be replaced with a variable, so the different $\textbf{s}'_i$ can be encoded. The $rlk$ generation process for a single $\textbf{s}_i$ is illustrated in Algorithm \ref{alg:ModuleRLKGeneration}, where $\textbf{s}'$ represents the individual $s_i\cdot \textbf{s}$ values. However, $n$ $rlk$ values, as one is required for each $\textbf{s}'_i$, need to be created in order to encode the whole $\textbf{s} \otimes \textbf{s}$ matrix. The full $rlk$ generation can be found in algorithm \ref{alg:HomomorphKeyGen}.


\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $\textbf{s}$, $\textbf{s}'=s_i\cdot\textbf{s}$
    \STATE $\textbf{A} \leftarrow R_{p \cdot q}^{n \times n}$
    \STATE $\textbf{e} \leftarrow \chi_R^{'n}$
    \STATE $\textbf{b} = [\textbf{A}\cdot \textbf{s}+\textbf{e}+p\cdot \textbf{s}']_{p \cdot q}$
    \RETURN $rlk:=(\textbf{A}_{s'}, \textbf{b}_{s'})$
  \end{algorithmic}
  \caption{M-LWE: $rlk$ Generation for a single $\textbf{s}_i$}
  \label{alg:ModuleRLKGeneration}
\end{algorithm}

As before, the $rlk$ can be used to create two values, $\textbf{xu}_m$ and $xv_m$. These values will be added to $\textbf{u}_m \in R^n_q$ and $v_m \in R_q$, respectively. Therefore, it is necessary for these values to have the same shape. However, as the encryption process used near identical formulas, the correct shapes come by themselves. Thus, equation \ref{eq:ringXmSplitting} can be translated into M-LWE, as shown in equation \ref{eq:moduleXmSplitting}. 

\begin{equation}
  (\textbf{xu}_m, xv_m) = \left(\sum_{i=0}^{n-1}\left[\left\lfloor\frac{\textbf{A}_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q, \sum_{i=0}^{n-1}\left[\left\lfloor \frac{b_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q\right)
  \label{eq:moduleXmSplitting}
\end{equation}

All this can be combined now into a single M-LWE multiplication algorithm, as seen in \ref{alg:moduleMultiplication}. And the new updated Key Generation, with the generation of the $rlk$ can be seen in \ref{alg:HomomorphKeyGen}.

\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \REQUIRE $rlk=((\textbf{A}_{\textbf{s}'_0}, \textbf{b}_{\textbf{s}'_0}), \ldots ,(\textbf{A}_{\textbf{s}'_{n-1}}, \textbf{b}_{\textbf{s}'_{n-1}}))$, $ct_1 = (\textbf{u}_1, v_1)$, $ct_2 = (\textbf{u}_2, v_2)$
    \STATE $v_m = \left[\left\lfloor \frac{2}{q}\cdot (v_1 \cdot v_2)\right\rceil\right] _q $
    \STATE $\textbf{u}_m = \left[\left\lfloor \frac{2}{q}\cdot(v_1 \cdot \textbf{u}_2 + v_2 \cdot \textbf{u}_1)\right\rceil\right] _q$
    \STATE $\textbf{x}_m = \left(\left[\left\lfloor \frac{2}{q}\cdot(u_{10} \cdot \textbf{u}_2)\right\rceil\right]_q,\cdots, \left[\left\lfloor \frac{2}{q}\cdot(u_{1n-1} \cdot \textbf{u}_2)\right\rceil\right]_q\right) $
    \STATE $\textbf{xu}_m = \sum_{i=0}^{n-1}\left[\left\lfloor\frac{\textbf{A}_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q$
    \STATE $xv_m = \sum_{i=0}^{n-1}\left[\left\lfloor \frac{b_{\textbf{s}'_i} \cdot \textbf{x}_{mi}}{p}  \right\rceil \right]_q$
    \RETURN $ct_m:=(\left[\textbf{u}_m + \textbf{xu}_m\right]_q , \left[v_m + xv_m\right]_q )$
  \end{algorithmic}
  \caption{M-LWE: Multiplication}
  \label{alg:moduleMultiplication}
\end{algorithm}


\begin{algorithm}[htb]
  \begin{algorithmic}[1]
    \STATE $\textbf{s} \leftarrow \chi_R^n$
    \STATE $\textbf{A} \leftarrow R^{n \times n}$
    \STATE $\textbf{e} \leftarrow \chi_R^n$
    \STATE $\textbf{b} = \textbf{A}\cdot \textbf{s}+\textbf{e}$
    \STATE $rlk = ()$
    \FOR{$i=0$ \textbf{to} $n-1$}
    \STATE $\textbf{A}_i \leftarrow R_{p \cdot q}^{n \times n}$
    \STATE $\textbf{e}_i \leftarrow \chi_R^{'n}$
    \STATE $\textbf{b}_i = [\textbf{A}_i\cdot \textbf{s}+\textbf{e}_i+p\cdot \textbf{s} \cdot s_i]_{p \cdot q}$
    \STATE $rlk_i = (\textbf{A}_i, \textbf{b}_i)$
    \ENDFOR
    \RETURN $(pk:=(\textbf{A}, \textbf{b}), sk:=\textbf{s}, rlk:= rlk )$
  \end{algorithmic}
  \caption{M-LWE: KeyGen}
  \label{alg:HomomorphKeyGen}
\end{algorithm}

\subsection*{Generate R-LWE from M-LWE}

One simple method for evaluating the efficacy of the generalization is to generate the R-LWE scheme from the M-LWE scheme with $n=1$. The initial step is to calculate the $rlk$. With a dimension of $1$, there is only a single $rlk$, which is calculated with $s'_0 = s_0 \cdot \textbf{s} = s_0 \cdot s_0 = s^2$. It can be seen that the M-LWE $rlk(s, s^2)$ (see algorithm \ref{alg:ModuleRLKGeneration}) is identical to the R-LWE $rlk(s)$ (see algorithm \ref{alg:RingRLKGeneration}), as both $A^{1 \times 1}$ and $e^1$ are single polynomials. As with $s$, the vector $\textbf{u}$ is a single polynomial. Consequently, the calculation of $u_m$ is identical between M-LWE (algorithm \ref{alg:moduleMultiplication}) and R-LWE (algorithm \ref{alg:RingMultiplication}). Furthermore, only a single $x_m$ value is required in M-LWE (as $n=1$), which is then used to calculate both $xu$ and $xv$, which are also single polynomials. Therefore, the entire calculation is identical to the R-LWE multiplication, which is a positive indication.


\section{Criteria for comparing LWE-based homomorphic encryption schemes}
\label{sec:HomomorphCriteria}

In order to conduct a comparative analysis of homomorphic encryption schemes, the same methodology previously outlined in Section \ref{sec:LweComparisonCriteria} can be employed to evaluate the underlying encryption and decryption mechanisms. To assess the homomorphic properties, the tests must be expanded. The first extension to the \textit{size cost} test is to include the relinearization key ($rlk$) in the evaluation. This entails computing the size of the $rlk$ and comparing it between the schemes. The \textit{time cost} test can be extended by also including the Addition and Multiplication algorithms into the tests and extending the KeyGen algorithm to include the generation of the relinearization key.

Moreover, the additive and multiplicative depth should be identified. This allows for the assessment of the number of consecutive calculations that can be performed while maintaining the ability to successfully decrypt the ciphertext. To enhance the precision of the predictions, it is essential to examine the evolution of the errors associated with addition and multiplication. This enables a more accurate understanding of the impact of the variables and depth on the outcomes.
